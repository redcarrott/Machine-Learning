{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4c7270",
   "metadata": {},
   "source": [
    "## OutdoorSeating BERT\n",
    "\n",
    "To adapt to a different attribute of interest, look out for `#change attribute` and replace with attribute name (ie. \"OutdoorSeating\") -- spelling must be correct! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a3d0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2083affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"OutdoorSeating_>49.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038ba569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>OutdoorSeating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Very relax friendly environment, the sandwic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Fun visit. Pizza crust was firm and crunchy....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Great new E Milton Square spot - love sittin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  OutdoorSeating\n",
       "0  ['Very relax friendly environment, the sandwic...               1\n",
       "1  ['Fun visit. Pizza crust was firm and crunchy....               1\n",
       "2  ['Great new E Milton Square spot - love sittin...               1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "077a93b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2957\n",
       "0    2957\n",
       "Name: OutdoorSeating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.OutdoorSeating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0ffe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = reviews[\"text\"]\n",
    "labels = reviews[\"OutdoorSeating\"] #change attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a339fb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['Very relax friendly environment, the sandwic...\n",
       "1    ['Fun visit. Pizza crust was firm and crunchy....\n",
       "2    ['Great new E Milton Square spot - love sittin...\n",
       "3    [\"Customer service was very good; the employee...\n",
       "4    [\"Delicious food and friendly service.  We had...\n",
       "5    [\"Cedar Hills has been ready for more elevated...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8942c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "Name: OutdoorSeating, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0d3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512 #max token length BERT will take in according to paper https://arxiv.org/pdf/1905.05583.pdf\n",
    "batch_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba38539",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "def convert_to_feature(review):\n",
    "    \"\"\"one-stop step to tokenize, WordPiece vector map, add special tokens,\n",
    "    and truncate reviews longer than max length\"\"\"\n",
    "    return tokenizer.encode_plus(review,\n",
    "                                add_special_tokens = True, #add [CLS] and [SEP] tokens\n",
    "                                truncation = True, \n",
    "                                padding = \"max_length\", #add [PAD] tokens for reviews shorter than max_length\n",
    "                                return_attention_mask = True, #add attention mask to not focus on [PAD]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba835696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1037, 3231, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_feature(\"This is a test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62cec10",
   "metadata": {},
   "source": [
    "## Training Dataset\n",
    "### x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6e9a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_texts(texts):\n",
    "    \"\"\"create lists to build final TensorFlow dataset\"\"\"\n",
    "    \n",
    "    input_ids_list = []\n",
    "    token_type_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    label_list = []\n",
    "    i = 0\n",
    "    \n",
    "    for review in texts:\n",
    "\n",
    "        bert_input = convert_to_feature(review)\n",
    "\n",
    "        input_ids_list.append(bert_input['input_ids'])\n",
    "        token_type_ids_list.append(bert_input['token_type_ids'])\n",
    "        attention_mask_list.append(bert_input['attention_mask'])\n",
    "        i += 1\n",
    "        \n",
    "    bert_inputs = np.array([input_ids_list, attention_mask_list, token_type_ids_list])\n",
    "        \n",
    "    return bert_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e20d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = encode_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce27023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5914, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "677e0e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5914, 512)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29dfb54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101,  1031,  1005,  2200,  9483,  5379,  4044,  1010,  1996,\n",
       "       22094,  2024,  2307,  2003,  2066,  2042,  2067,  2188,  1012,\n",
       "        1996,  2047,  3295,  2003,  2126,  7046,  2061,  2003,  2428,\n",
       "       22445,  2061,  2111,  2064,  2835,  1998,  5959,  2037,  7954,\n",
       "        1012,  2023,  2003,  2026,  3962,  2320,  1037,  2733,  2005,\n",
       "        6350,  1005,  1010,  1005,  2028,  1997,  2026,  5440,  3182,\n",
       "        2000,  2175,  2005,  6350,   999,  2027,  4423,  1998,  2027,\n",
       "        7597,  2205,  1012,  2021,  3452,  2204,  2173,  1010,  2200,\n",
       "        2714,  2000,  5984, 14735,  2078,  2806, 16673,  1012,  1005,\n",
       "        1010,  1000,  2023,  2003,  2026,  5440,  2173,  2000,  4521,\n",
       "        2043,  1045,  1005,  1049,  2006,  2023,  2217,  1997,  2237,\n",
       "         999,  3251,  2009,  1005,  1055,  2005,  6350,  1010,  6265,\n",
       "        2030,  2130, 18064,  1010,  2673, 23651,  2026, 10908,  1012,\n",
       "        1996,  7861,  9739,  8447,  2015,  2024,  2026,  5440,  1012,\n",
       "        1996,  4825,  2003,  2036,  2467,  4550,  1998,  3095,  2003,\n",
       "        2467,  5379,   999,  1019,  2732,  2833,  1010,  7224,  1004,\n",
       "        2326,  1000,  1010,  1000,  1045,  2253,  1999,  4851,  2005,\n",
       "        1996,  2235, 19739, 12462, 22619,  1998,  2179,  2041,  2027,\n",
       "        2018,  2000,  2022,  3641,  2007, 11162,  1012,  2174,  1996,\n",
       "        3095,  2001,  2061, 14044,  1998,  3835,  2008,  2027,  4810,\n",
       "        2068,  2157,  2185,  1012,  1045,  1005,  1049,  2061,  5580,\n",
       "        2138,  2027,  2024, 12090,  1012,  2005,  2469,  1045,  1005,\n",
       "        1049,  2183,  2000,  3942,  2178,  2051,  1006,  2044,  2035,\n",
       "        1045,  4033,  1005,  1056,  2699,  2037, 22094,  1010,  2029,\n",
       "        4025,  8053, 26380,  1007,  1012,  1045,  3811, 16755,  2037,\n",
       "        2627,  5134,  1012,  3835,  2173,  2007,  2307,  2111,  1012,\n",
       "        1000,  1010,  1000,  6719,  2234,  2182,  3807,  1999,  1037,\n",
       "        2733,  1012,  1996,  2034,  2051,  1045,  2253,  2005,  6265,\n",
       "        1012,  1045,  2001,  4527,  2027,  2018,  2632, 17695, 27703,\n",
       "        2015,  1012,  1012,  2026,  5440,  1012,  2025,  1037,  2843,\n",
       "        1997,  2111,  2191,  2068,  1998,  2043,  2027,  2079,  2027,\n",
       "        2123,  1005,  1056,  4025,  2000,  2022,  2008,  2204,  1012,\n",
       "        2027,  2018,  1037,  2204,  3815,  1997, 14894,  1998,  6240,\n",
       "        1999,  2068,  1012,  1045,  4207,  1037, 13843,  3630,  2569,\n",
       "       11642,  2007,  2026,  3566,  1012,  2008, 11642,  2003,  6429,\n",
       "         999,  2926,  2043,  8209,  2039,  2007,  1996, 14415, 17710,\n",
       "       10649,  6279, 12901,  1012,  1996,  2117,  2051,  1045,  2253,\n",
       "        2057,  2288,  6350,  1012,  9781,  7954,  2005,  1996,  2663,\n",
       "        1012,  1057,  5603,  1045,  2031,  2042, 26369,  2009,  2412,\n",
       "        2144,  1012,  1996,  7597,  2024,  2428,  2204,  1998,  1996,\n",
       "        4825,  2003,  4550,  1998,  2330,  2348,  2049,  7887,  8966,\n",
       "        1012,  1012,  1996,  2240,  5829,  3435,  2061,  2123,  1005,\n",
       "        1056,  2681,  1012,  1000,  1010,  1000,  2307,  2833,  2021,\n",
       "        2123,  1005,  1056,  2344,  3784,  1012,  2256,  2344,  2001,\n",
       "        4011,  2000,  2022,  3201,  2012,  2340,  1024,  5709,  2050,\n",
       "        1010,  2009,  2001,  2025,  1010,  2057,  2203,  2039,  2975,\n",
       "        1996,  2173,  2012,  2340,  1024,  2382,  2050,  1998,  2043,\n",
       "        2057,  2288,  2188,  2057,  4384,  2008,  2070,  1997,  2256,\n",
       "        2344,  2001,  3308,  1010,  2027,  2435,  2149,  1996,  3308,\n",
       "        2518,  1012,  2320,  2153,  1996,  2833,  2009,  1005,  1055,\n",
       "        2307,  2021,  1045,  2228,  2144,  2023,  2173,  2003,  2467,\n",
       "        5308,  2027,  2123,  1005,  1056,  2031,  1996,  2051,  2000,\n",
       "        3477,  3086,  2000,  1996,  3784,  4449,  1012,  1000,  1010,\n",
       "        1005,  1045,  2031,  2042,  5782,  2000,  3046,  2023,  2173,\n",
       "        2005,  1037,  2096,  1012,  2027,  2074,  4423,  1998,  2027,\n",
       "        2428,  2734,  2009,  1012,  2045,  2001,  1037,  2240,  2006,\n",
       "        5095,  2851,  1012,  1996,  3524,  2001,  2025,   102])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_1[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bed1fa5",
   "metadata": {},
   "source": [
    "### y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0f0cad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5914"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f04283ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5914,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1 = np.array(labels)\n",
    "y_train_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b66806",
   "metadata": {},
   "source": [
    "## Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7277c3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00a7ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(x_train_1[0])\n",
    "np.random.seed(0)\n",
    "training_examples = np.random.binomial(1, 0.8, numSentences)\n",
    "\n",
    "trainSentence_ids = []\n",
    "trainMasks = []\n",
    "trainSequence_ids = []\n",
    "\n",
    "testSentence_ids = []\n",
    "testMasks = []\n",
    "testSequence_ids = []\n",
    "\n",
    "Labels_train =[]\n",
    "Labels_test = []\n",
    "\n",
    "\n",
    "for example in range(numSentences):\n",
    "    if training_examples[example] == 1:\n",
    "        trainSentence_ids.append(x_train_1[0][example])\n",
    "        trainMasks.append(x_train_1[1][example])\n",
    "        trainSequence_ids.append(x_train_1[2][example])\n",
    "        Labels_train.append(y_train_1[example])\n",
    "    else:\n",
    "        testSentence_ids.append(x_train_1[0][example])\n",
    "        testMasks.append(x_train_1[1][example])\n",
    "        testSequence_ids.append(x_train_1[2][example])\n",
    "        Labels_test.append(y_train_1[example])\n",
    "        \n",
    "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
    "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
    "\n",
    "Y_train = np.array(Labels_train).astype('float32').reshape((-1,1))\n",
    "Y_test = np.array(Labels_test).astype('float32').reshape((-1,1))\n",
    "\n",
    "X_train = [X_train[0], X_train[1], X_train[2]]\n",
    "X_test = [X_test[0], X_test[1], X_test[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0e702",
   "metadata": {},
   "source": [
    "## BERT Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0501a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d157f",
   "metadata": {},
   "source": [
    "### BERT base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecf5eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT_model(max_input_length, train_layers, optimizer):\n",
    "    \"\"\"\n",
    "    variables:\n",
    "        max_input_length: number of tokens (max_length + 1)\n",
    "        train_layers: number of layers to be retrained\n",
    "        optimizer: optimizer to be used\n",
    "    \n",
    "    returns: model\n",
    "    \"\"\"\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_input_length,), dtype='int32', name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_input_length,), dtype='int32', name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_input_length,), dtype='int32', name=\"segment_ids\")\n",
    "    \n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "       \n",
    "    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n",
    "    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n",
    "\n",
    "    bert_layer = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    bert_sequence = bert_layer(bert_inputs)[0]\n",
    "    \n",
    "    print('Let us check the shape of the BERT layer output:', bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n",
    "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "\n",
    "    dense1 = tf.keras.layers.Dense(64, activation='relu', name='dense1')(dense)\n",
    "    dense1 = tf.keras.layers.Dropout(rate=0.1)(dense1)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(dense1) # binary activation output\n",
    "  \n",
    "    print('pred: ', pred)    \n",
    "      \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64020732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 512, 768), dtype=tf.float32, name=None), name='tf_bert_model_2/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model_2'\")\n",
      "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 512, 1), dtype=tf.float32, name=None), name='classifier/Sigmoid:0', description=\"created by layer 'classifier'\")\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_masks (InputLayer)       [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_2 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'input_masks[0][0]',            \n",
      "                                tentions(last_hidde               'segment_ids[0][0]']            \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512, 256)     196864      ['tf_bert_model_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_115 (Dropout)          (None, 512, 256)     0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 512, 64)      16448       ['dropout_115[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)          (None, 512, 64)      0           ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 512, 1)       65          ['dropout_116[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,695,617\n",
      "Trainable params: 109,695,617\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = BERT_model(\n",
    "    max_length, \n",
    "    train_layers = 0, \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4e18d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4739, 512)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be1152f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4739, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "faf8f2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1175, 512)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a1aca6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1175, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fe0f356",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "297/297 [==============================] - 1015s 3s/step - loss: 0.7367 - accuracy: 0.4951 - val_loss: 0.6939 - val_accuracy: 0.4689\n",
      "Epoch 2/5\n",
      "297/297 [==============================] - 976s 3s/step - loss: 0.6933 - accuracy: 0.5035 - val_loss: 0.6945 - val_accuracy: 0.4689\n",
      "Epoch 3/5\n",
      "297/297 [==============================] - 988s 3s/step - loss: 0.6933 - accuracy: 0.5051 - val_loss: 0.6948 - val_accuracy: 0.4689\n",
      "Epoch 4/5\n",
      "297/297 [==============================] - 1113s 4s/step - loss: 0.6932 - accuracy: 0.5077 - val_loss: 0.6937 - val_accuracy: 0.4689\n",
      "Epoch 5/5\n",
      "297/297 [==============================] - 1065s 4s/step - loss: 0.6933 - accuracy: 0.5077 - val_loss: 0.6948 - val_accuracy: 0.4689\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=5, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
